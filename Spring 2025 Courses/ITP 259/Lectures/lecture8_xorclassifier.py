# -*- coding: utf-8 -*-
"""Lecture8_XORClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X_POquySNzblYw3BzrRCClIvztxXd6xO
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.neural_network import MLPClassifier

# Read the csv file
df = pd.read_csv("sample_data/XOR.csv")

# Set X and y
X=df.iloc[:,0:2]
y=df.iloc[:,2]
print(X)
print(X.shape)
print(y)
print(y.shape)

# Visualize the xor distribution
plt.scatter(x=X.iloc[:,0], y=X.iloc[:,1], c=y)
plt.xlabel('x')
plt.ylabel('y')
plt.title('XOR Plot')

plt.show()

# Train test partitions
X_train, X_test , Y_train, Y_test = \
    train_test_split(X, y,test_size=0.30, random_state=2022, stratify=y)
#
# print(X_train)
# print(X_test)
# print(Y_train)
# print(Y_test)

# Instantiate MLPClassifier
# Note the hidden layers and neurons on each layer
mlp = MLPClassifier(hidden_layer_sizes=(5,5), activation="tanh",
                    max_iter=1000, alpha=1e-3, solver="adam",
                    random_state=2022, learning_rate_init=0.01, verbose=True)

# Training
mlp.fit(X_train, Y_train)

# Plot loss curve
plt.plot(mlp.loss_curve_)
plt.show()

# Accuracy
print("The accuracy is", mlp.score(X_test,Y_test))

# Confusion matrix
y_pred = mlp.predict(X_test)

cm = confusion_matrix(Y_test, y_pred, labels=mlp.classes_)
ConfusionMatrixDisplay(confusion_matrix=cm).plot()
plt.show()

# Plot the decision boundary. Create a mesh of x and y points. Then
# predict the label. Then plot those with color.
X1 = np.arange(-2, 2, 0.01)
X2 = np.arange(-2, 2, 0.01)

X1, X2 = np.meshgrid(X1, X2)

X_decision = pd.DataFrame({"X0": np.reshape(X1,160000), "X1": np.reshape(X2,160000)})
Z = mlp.predict(X_decision)

plt.scatter(x=X_decision["X0"],y=X_decision["X1"], c=Z, cmap="BuGn")
plt.scatter(x=X.iloc[:,0], y=X.iloc[:,1], c=y)
plt.show()