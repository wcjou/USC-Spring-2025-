# -*- coding: utf-8 -*-
"""Lecture9_digits.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bbwzy81flyzM7Ue81aBNJF3K3-8BO7iL
"""

import random
import pandas as pd
import seaborn as sb
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV

train_df = pd.read_csv("sample_data/mnist_train.csv")
test_df = pd.read_csv("sample_data/mnist_test.csv")

train_df.head()
# test_df.head()

plt.figure(1)
sb.countplot(x="label", data=train_df)
plt.show()

pixel = train_df.iloc[15,1:]

print("The digit is ", train_df.iloc[15,0])

print(pixel)
print(pixel.shape)

#pixel = np.array(pixel)
#print(pixel.shape)
pixel = pixel.reshape(28,28)
print(pixel)

plt.imshow(pixel, cmap="gray")
# plt.show()

X_train = train_df.iloc[:,1:]
Y_train = train_df.iloc[:,0]
X_test = test_df.iloc[:,1:]
Y_test = test_df.iloc[:,0]
print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

import random
import pandas as pd
import seaborn as sb
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV

# Import datasets
train_df = pd.read_csv("sample_data/mnist_train.csv")
test_df = pd.read_csv("sample_data/mnist_test.csv")

################ EXPLORE & SHAPE THE DATASET ################
print(train_df.head())
print(test_df.head())

# Explore the distribution of digits in the train dataset
plt.figure(1)
sb.countplot(x="label", data=train_df)
plt.show()

# Visualize the first digit in the training dataset
print("The digit is ", train_df.iloc[0,0])
pixel = train_df.iloc[0,1:]
print(pixel)

# Shape pixels as a 28x28 array
pixel = np.array(pixel)
pixel = pixel.reshape(28,28)
print(pixel)

# Plot pixel array
plt.imshow(pixel, cmap="gray")
plt.show()

# Train test datasets; as always drop target vector and put in separate variable
X_train = train_df.iloc[:,1:]
Y_train = train_df.iloc[:,0]
X_test = test_df.iloc[:,1:]
Y_test = test_df.iloc[:,0]
print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)

# Scale the feature set
X_train_scaled = X_train/255
X_test_scaled = X_test/255

################ TRAINING THE MODEL ################
# Instantiate MLPClassifier
# Three hidden layers each with 100 neurons
mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), activation="relu",
                    max_iter=25, alpha=1e-3, solver="adam",
                    random_state=2022, learning_rate_init=0.01, verbose=True)

# Train the model
mlp.fit(X_train_scaled, Y_train)

# Plot loss curve
plt.plot(mlp.loss_curve_)
plt.show()

# Accuracy
print("The accuracy is", mlp.score(X_test_scaled.values,Y_test))

# Confusion matrix
y_pred = mlp.predict(X_test.values)
cm = confusion_matrix(y_pred, Y_test)
ConfusionMatrixDisplay(confusion_matrix=cm).plot()
plt.show()
# print("The confusion matrix", cm)

# Predict
image_number = random.randint(0, 10000)
print(image_number)
test_sample = np.array(X_test.iloc[image_number]).reshape(28, 28)
plt.imshow(test_sample, cmap="gray")
plt.title("The predicted digit is "+ str(y_pred[image_number]) + ". The human label was " + str(Y_test[image_number]))
plt.show()

# Display a failed prediction
# Filter the test dataframe to those cases where the prediction failed
failed_df = X_test[y_pred != Y_test]
# failed_df is a dataframe with 255 rows and 784 columns. The index is filtered from X_Test
# where the predicted and actual y did not match.
print("Dataframe of incorrect predictions ", failed_df)
print("The number of failed prediction is ", )

# Pick a random row index from the failed dataframe
failed_index = failed_df.sample(n=1).index
print("The index of the row of a random incorrect prediction ", failed_index.values)

# Now unflatten the row at the failed index.
failed_sample = np.array(X_test.iloc[failed_index]).reshape(28, 28)
# print("The failed sample is ", failed_sample)

# plot the incorrectly predicted digit.
# Show its actual and its predicted values
plt.imshow(failed_sample, cmap="gray")

# y_pred is a 1D numpy array. (10000, ). We can access an array element
# with an index number which is the same index as the failed_index.
# Y_test is a pandas series. We can access its value using the same
# index as the failed_index.

plt.title("The failed predicted digit is "+ str(y_pred[failed_index]) +
          " whereas the actual digit is " + str(Y_test[failed_index].values))
                # note the difference between accessing the values of a numpy array and a pandas series
plt.show()

# How many features in the input layer?
print("Features ", mlp.n_features_in_)

# How many hidden layers?
print("Layers ", mlp.n_layers_)

# How many neurons per hidden layer?
print("Neurons per hidden layer ", mlp.hidden_layer_sizes)

# How many neurons in the output layer?
print("Number of outputs ", mlp.n_outputs_)

#### Grid Search ####

# param_grid = {
#     'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],
#     'max_iter': [50, 100, 150],
#     'activation': ['tanh', 'relu'],
#     'solver': ['sgd', 'adam'],
#     'alpha': [0.0001, 0.05],
#     'learning_rate': ['constant','adaptive'],
# }

# grid = GridSearchCV(mlp, param_grid, n_jobs= -1, cv=5)
# grid.fit(X_train, Y_train)

# print(grid.best_params_)
# grid_predictions = grid.predict(X_test)
# print('Accuracy: {:.2f}'.format(accuracy_score(Y_test, grid_predictions)))

