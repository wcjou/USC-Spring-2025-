# -*- coding: utf-8 -*-
"""Lecture10_Multi_Regression_Cali.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b2w9B3umbVYA5vQdlvg2mlqCqwLxqP2M
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.datasets import fetch_california_housing

# Load the California Housing dataset
# housing_dataset = fetch_california_housing(as_frame=True)
# housing = housing_dataset.frame
# display(housing)
# print(housing.head())

housing = pd.read_csv("housing.csv")
display(housing)
print(housing.head())

# Check for missing values
print(housing.isnull().sum())

# Plot the distribution of the target variable (MedHouseVal)
sns.displot(housing['median_house_value'], bins=30)
plt.show()

# Correlation matrix
# correlation_matrix = housing.corr().round(2)
# sns.heatmap(data=correlation_matrix, annot=True)
# plt.show()

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_california_housing

# Load the dataset
housing = pd.read_csv("housing.csv")

# Check for missing values
print(housing.isnull().sum())

# Select features and target
X1 = housing[['median_income']]
X2 = housing[['median_income', 'total_rooms']]
Y = housing['median_house_value']

# Split data
X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y, test_size=0.3, random_state=5)
X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y, test_size=0.3, random_state=5)

# Apply Standard Scaling
scaler1 = StandardScaler()
scaler2 = StandardScaler()

X_train1_scaled = scaler1.fit_transform(X_train1)
X_test1_scaled = scaler1.transform(X_test1)

X_train2_scaled = scaler2.fit_transform(X_train2)
X_test2_scaled = scaler2.transform(X_test2)

# Train linear models
lin_model1 = LinearRegression()
lin_model1.fit(X_train1_scaled, Y_train1)

lin_model2 = LinearRegression()
lin_model2.fit(X_train2_scaled, Y_train2)

# Train neural network models
NN_model1 = MLPRegressor(hidden_layer_sizes=(50, 50, 50), activation="tanh",
                         max_iter=2000, alpha=0.0001, solver="sgd",
                         random_state=2022, learning_rate_init=0.01, learning_rate='adaptive')

### TRY RELU
NN_model2 = MLPRegressor(hidden_layer_sizes=(50, 50), activation="tanh",
                         max_iter=2000, alpha=0.0001, solver="sgd",
                         random_state=2022, learning_rate_init=0.01, learning_rate='adaptive')

NN_model1.fit(X_train1_scaled, Y_train1)
NN_model2.fit(X_train2_scaled, Y_train2)

# Predictions and RMSE calculations
y_test_predict1 = lin_model1.predict(X_test1_scaled)
rmse_test1 = np.sqrt(mean_squared_error(Y_test1, y_test_predict1))

y_test_predict2 = lin_model2.predict(X_test2_scaled)
rmse_test2 = np.sqrt(mean_squared_error(Y_test2, y_test_predict2))

y_test_predictNN1 = NN_model1.predict(X_test1_scaled)
rmse_test1_NN1 = np.sqrt(mean_squared_error(Y_test1, y_test_predictNN1))

y_test_predictNN2 = NN_model2.predict(X_test2_scaled)
rmse_test2_NN2 = np.sqrt(mean_squared_error(Y_test2, y_test_predictNN2))

# Print results
print("Linear Model RMSE:")
print(f"Median Income: {rmse_test1}")
print(f"Median Income & Total Bedrooms: {rmse_test2}")

print("\nNeural Network RMSE:")
print(f"NN1 - Median Income: {rmse_test1_NN1}")
print(f"NN2 - Median Income & Total Bedrooms: {rmse_test2_NN2}")

# Plot results
plt.figure(figsize=(12, 5))

# Single feature plot
plt.subplot(1, 2, 1)
plt.scatter(X_test1, Y_test1, alpha=0.5, label="Data")
plt.plot(X_test1, y_test_predict1, color="blue", label="Linear Model")
plt.scatter(X_test1, y_test_predictNN1, color="red", s=10, label="Neural Network")
plt.xlabel("Median Income")
plt.ylabel("Median House Value")
plt.title("Comparison for One Feature")
plt.legend()

# Two feature plot
plt.subplot(1, 2, 2)
plt.scatter(Y_test2, y_test_predict2, alpha=0.5, label="Linear Model", color="blue")
plt.scatter(Y_test2, y_test_predictNN2, alpha=0.5, label="Neural Network", color="red")
plt.xlabel("Actual Median House Value")
plt.ylabel("Predicted Median House Value")
plt.title("Comparison for Two Features")
plt.legend()

plt.tight_layout()
plt.show()