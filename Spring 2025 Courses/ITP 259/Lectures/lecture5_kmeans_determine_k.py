# -*- coding: utf-8 -*-
"""Lecture5_kMeans_determine_k.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18CcXzJrmUHDm03IVkV9qBcxgVUiu33R4
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import Normalizer

wineData = pd.read_csv("Spring 2025 Courses/ITP 259/Homework/HW1/Jou_William_hw1/wineQualityReds.csv")

pd.set_option("display.max_columns", None)

wineData.drop(wineData.columns[0], axis=1, inplace=True)
print(wineData)
# print("\n \n")

norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)
# wineData_norm = wineData

# Lets see what effect the normalization has:
# wineData_norm = wineData

print(wineData_norm)

# g = sns.pairplot(wineData_norm, markers='+')
# plt.show()

# Compute and plot inertias (WCSS) for various k = number of clusters
ks = range(1,10)
inertias = []
for k in ks:
    model = KMeans(n_clusters=k)
    model.fit(wineData_norm)
    inertias.append(model.inertia_)

# Plot inertias vs. k
plt.plot(ks, inertias, "-o")
plt.xlabel("Number of Clusters, k")
plt.ylabel("Inertia")
plt.xticks(ks)
plt.show()

# Silouette Method to determine the optimal k

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

wineData = pd.read_csv("sample_data/wineQualityReds.csv")

pd.set_option("display.max_columns", None)

wineData.drop(wineData.columns[0], axis=1, inplace=True)

norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)
# wineData_norm = wineData

# Compute and plot Silhouettes for various k = number of clusters

kmax = 10
ks = range(2,kmax+1)
sil = []
for k in ks:
  model = KMeans(n_clusters = k)
  model.fit(wineData_norm)
  sil.append(silhouette_score(wineData_norm, model.labels_, metric = 'euclidean'))

# Plot Silhouettes vs. k
plt.plot(ks, sil, "-o")
plt.xlabel("Number of Clusters, k")
plt.ylabel("Silhouette Scores")
plt.xticks(ks)
plt.show()

"""# Lets try a different data set"""

# A different Data Set from Kaggle

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import Normalizer

wineData = pd.read_csv("sample_data/Wine_Kaggle.csv")

pd.set_option("display.max_columns", None)

# print(wineData)
# print("\n \n")

wineData.drop(wineData.columns[13], axis=1, inplace=True)

norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)

# Lets see what effect the normalization has:
# wineData_norm = wineData

print(wineData_norm)

# g = sns.pairplot(wineData_norm, markers='+')
# plt.show()

# Compute and plot inertias (WCSS) for various k = number of clusters
ks = range(1,11)
inertias = []
for k in ks:
    model = KMeans(n_clusters=k)
    model.fit(wineData_norm)
    inertias.append(model.inertia_)

# Plot inertias vs. k
plt.plot(ks, inertias, "-o")
plt.xlabel("Number of Clusters, k")
plt.ylabel("Inertia")
plt.xticks(ks)
plt.show()

# Silouette Method to determine the optimal k

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

wineData = pd.read_csv("sample_data/Wine_Kaggle.csv")

pd.set_option("display.max_columns", None)

wineData.drop(wineData.columns[13], axis=1, inplace=True)

norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)
# wineData_norm = wineData

# Compute and plot Silhouettes for various k = number of clusters

kmax = 10
ks = range(2,kmax+1)
sil = []
for k in ks:
  model = KMeans(n_clusters = k)
  model.fit(wineData_norm)
  sil.append(silhouette_score(wineData_norm, model.labels_, metric = 'euclidean'))

# Plot Silhouettes vs. k
plt.plot(ks, sil, "-o")
plt.xlabel("Number of Clusters, k")
plt.ylabel("Silhouette Scores")
plt.xticks(ks)
plt.show()

"""# Do This: create a model with 6 clusters. Fit the model to the Wine Data. Print the labels. Add labels to the Wine Data."""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

wineData = pd.read_csv("sample_data/wineQualityReds.csv")
pd.set_option("display.max_columns", None)
wineData.drop(wineData.columns[0], axis=1, inplace=True)
norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)

# create model with 6 clusters
model = KMeans(n_clusters=6, random_state=2020)

# fit model
model.fit(wineData_norm)

# add labels to the df
labels = model.predict(wineData_norm)

# add labels to normalized df
wineData_norm["Cluster Label"] = pd.Series(labels)

print(wineData_norm)

"""# Vizualization"""

# Lets visualize

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

wineData = pd.read_csv("sample_data/wineQualityReds.csv")
pd.set_option("display.max_columns", None)
wineData.drop(wineData.columns[0], axis=1, inplace=True)
norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)

# create model with 6 clusters
model = KMeans(n_clusters=6, random_state=2020)
# fit model
model.fit(wineData_norm)
# add labels to the df
labels = model.predict(wineData_norm)
# add labels to normalized df
wineData_norm["cluster"] = pd.Series(labels)

# get centroids
centroids = model.cluster_centers_
cen_x = [i[0] for i in centroids]
cen_y = [i[1] for i in centroids]

# add to dataframe
wineData_norm['cen_x'] = wineData_norm.cluster.map({0:cen_x[0], 1:cen_x[1], 2:cen_x[2], 3:cen_x[3], 4:cen_x[4], 5:cen_x[5]})
wineData_norm['cen_y'] = wineData_norm.cluster.map({0:cen_y[0], 1:cen_y[1], 2:cen_y[2], 3:cen_y[3], 4:cen_y[4], 5:cen_y[5]})

# define and map colors
colors = ['#DF2020', '#81DF20', '#2095DF', '#FA8072', '#6495ED', '#9FE2BF']
wineData_norm['c'] = wineData_norm.cluster.map({0:colors[0], 1:colors[1], 2:colors[2], 3:colors[3], 4:colors[5], 5:colors[5]})
print(wineData_norm)
print(wineData_norm.columns)

# Plot every variable against the last column (Quality)

plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,1], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,2], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,3], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,4], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,4], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,6], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,7], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,8], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,9], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,10], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()

# Lets visualize

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

wineData = pd.read_csv("sample_data/Wine_Kaggle.csv")
pd.set_option("display.max_columns", None)
wineData.drop(wineData.columns[13], axis=1, inplace=True)
norm = Normalizer()
wineData_norm = pd.DataFrame(norm.transform(wineData), columns=wineData.columns)

# create model with 3 clusters
model = KMeans(n_clusters=3, random_state=2020)
# fit model
model.fit(wineData_norm)
# add labels to the df
labels = model.predict(wineData_norm)
# add labels to normalized df
wineData_norm["cluster"] = pd.Series(labels)

print(wineData_norm)

# get centroids
centroids = model.cluster_centers_
cen_x = [i[0] for i in centroids]
cen_y = [i[1] for i in centroids]

# add centroids to dataframe
wineData_norm['cen_x'] = wineData_norm.cluster.map({0:cen_x[0], 1:cen_x[1], 2:cen_x[2]})
wineData_norm['cen_y'] = wineData_norm.cluster.map({0:cen_y[0], 1:cen_y[1], 2:cen_y[2]})

# define and map colors and add to df
colors = ['#DF2020', '#81DF20', '#2095DF']
wineData_norm['c'] = wineData_norm.cluster.map({0:colors[0], 1:colors[1], 2:colors[2]})
print(wineData_norm)
print(wineData_norm.columns)

# Plot every variable against the first column (Alcohol)

plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,1], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,2], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,3], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,4], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,5], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,6], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,7], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,8], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,9], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,10], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,12], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()

# Without normalization...

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

wineData = pd.read_csv("sample_data/Wine_Kaggle.csv")
pd.set_option("display.max_columns", None)
wineData.drop(wineData.columns[13], axis=1, inplace=True)
norm = Normalizer()
wineData_norm = wineData

# create model with 3 clusters
model = KMeans(n_clusters=3, random_state=2020)
# fit model
model.fit(wineData_norm)
# add labels to the df
labels = model.predict(wineData_norm)
# add labels to normalized df
wineData_norm["cluster"] = pd.Series(labels)

# get centroids
centroids = model.cluster_centers_
cen_x = [i[0] for i in centroids]
cen_y = [i[1] for i in centroids]

# add to dataframe
wineData_norm['cen_x'] = wineData_norm.cluster.map({0:cen_x[0], 1:cen_x[1], 2:cen_x[2]})
wineData_norm['cen_y'] = wineData_norm.cluster.map({0:cen_y[0], 1:cen_y[1], 2:cen_y[2]})

# define and map colors
colors = ['#DF2020', '#81DF20', '#2095DF']
wineData_norm['c'] = wineData_norm.cluster.map({0:colors[0], 1:colors[1], 2:colors[2]})
print(wineData_norm)
print(wineData_norm.columns)

# Plot every variable against the first column (Alcohol)

plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,1], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,2], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,3], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,4], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,5], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,6], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,7], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,8], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,9], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,10], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,11], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()
plt.scatter(wineData_norm.iloc[:,0], wineData_norm.iloc[:,12], c=wineData_norm.c, alpha = 0.6, s=10)
plt.show()