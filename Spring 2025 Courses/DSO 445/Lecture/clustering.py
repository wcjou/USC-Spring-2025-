# -*- coding: utf-8 -*-
"""clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SvYh1YEeIMjKKuvAfmz09kn2KIyZ8Wh2
"""

import pandas as pd
from sklearn.datasets import load_iris

# Load the iris dataset
iris_data = load_iris()
iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)

# Display the first few rows and summary statistics of the dataset
head_data = iris_df.head()
summary_data = iris_df.describe()

head_data, summary_data

from sklearn.preprocessing import StandardScaler

# Initialize the standard scaler
scaler = StandardScaler()

# Normalize the data
normalized_data = scaler.fit_transform(iris_df)

# Convert normalized data back to dataframe for better visualization
normalized_df = pd.DataFrame(normalized_data, columns=iris_data.feature_names)

# Display the first few rows and summary statistics of the normalized dataset
head_normalized = normalized_df.head()
summary_normalized = normalized_df.describe()

head_normalized, summary_normalized

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Define a range of clusters
cluster_range = range(1, 11)

# Compute KMeans for each number of clusters
inertias = []
for k in cluster_range:
    kmeans = KMeans(n_clusters=k, random_state=42).fit(normalized_data)
    inertias.append(kmeans.inertia_)

# Plot the Elbow method
plt.figure(figsize=(10,6))
plt.plot(cluster_range, inertias, marker='o', linestyle='--')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

inertias

from sklearn.metrics import silhouette_score

# Compute silhouette scores for each number of clusters
sil_scores = []
for k in cluster_range:
    kmeans = KMeans(n_clusters=k, random_state=42).fit(normalized_data)
    if k > 1:  # silhouette_score requires at least 2 clusters
        score = silhouette_score(normalized_data, kmeans.labels_)
        sil_scores.append(score)
    else:
        sil_scores.append(None)

# Plot the Silhouette scores
plt.figure(figsize=(10,6))
plt.plot(cluster_range, sil_scores, marker='o', linestyle='--')
plt.title('Silhouette Scores vs. Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

from sklearn.metrics import davies_bouldin_score

# Compute Davies-Bouldin scores for each number of clusters
db_scores = []
for k in cluster_range:
    kmeans = KMeans(n_clusters=k, random_state=42).fit(normalized_data)
    if k > 1:  # davies_bouldin_score requires at least 2 clusters
        score = davies_bouldin_score(normalized_data, kmeans.labels_)
        db_scores.append(score)
    else:
        db_scores.append(None)

# Plot the Davies-Bouldin scores
plt.figure(figsize=(10,6))
plt.plot(cluster_range, db_scores, marker='o', linestyle='--')
plt.title('Davies-Bouldin Scores vs. Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('Davies-Bouldin Score')
plt.grid(True)
plt.show()